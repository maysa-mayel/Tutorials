{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install Required Libraries**"
      ],
      "metadata": {
        "id": "9uYE6CkWQAv8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTujM5R4UpgP"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf langchain_openai langchain_community faiss-cpu google-colab --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Up Your OpenAI API**"
      ],
      "metadata": {
        "id": "v2599OoYQK2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set openai Key\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "# Access the secret and set it as an environment variable\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('openai')"
      ],
      "metadata": {
        "id": "dIAexrITVOZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define LLM"
      ],
      "metadata": {
        "id": "QyDb9MNAx0qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4\")\n",
        "llm.invoke(\"what can you help me with?\")"
      ],
      "metadata": {
        "id": "pUQnw6ZKVxFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading  PDF"
      ],
      "metadata": {
        "id": "oFwaxGVF0HNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader= PyPDFLoader(\"/content/attention is all you need.pdf\")\n",
        "pages= loader.load()"
      ],
      "metadata": {
        "id": "SKBd7tWr4BWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "parsing PDF"
      ],
      "metadata": {
        "id": "7vxbY_RNIoN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "text_splitter= CharacterTextSplitter(chunk_size=10, chunk_overlap=0)\n",
        "docs= text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "b20KBAX34o6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Documents into a Knowledge Base"
      ],
      "metadata": {
        "id": "QmJcFq252hm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "faiss_index= FAISS.from_documents(pages, OpenAIEmbeddings())\n",
        "faiss_index.save_local(\"attention is all you need\")"
      ],
      "metadata": {
        "id": "fkMUvXsWV2Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the saved embeddings"
      ],
      "metadata": {
        "id": "izfXbCodP69v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings= OpenAIEmbeddings()\n",
        "\n",
        "loaded_vectors= FAISS.load_local(\"attention is all you need\", embeddings, allow_dangerous_deserialization=True)"
      ],
      "metadata": {
        "id": "aZpp2Ux5VuvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rag Chain"
      ],
      "metadata": {
        "id": "szYrB2TYX8_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetravialChain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "QA= ConversationalRetravialChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=loaded_vectors.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "gXd6E-vpVqsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history=[]\n",
        "def rag(query):\n",
        "  response=QA({\"question\":query, \"chat_history\":chat_history})\n",
        "  chat_history.append((query, response['answer']))\n",
        "  return response['answer'].strip()"
      ],
      "metadata": {
        "id": "_KRTFd2TVOkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag(\"Can you summarize the key findings of the research?\")"
      ],
      "metadata": {
        "id": "dBW3qGshP9z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag(\"What are the benefits of using multi-head attention?\")"
      ],
      "metadata": {
        "id": "s0bj7UCpYHoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}